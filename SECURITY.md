# Security Policy

## üõ°Ô∏è Security Philosophy

AI PowerTools is designed on a **Privacy-First, Local-Default** architecture. We believe that AI engineering tools should not require trust in Third-Party providers for core functionality.

## üîí Best Practices for Developers

### 1. Secret Management
- **NEVER** commit API keys or credentials to the repository.
- Use `.env` files (ignored by Git) for local development.
- The `Privacy Layer` component (#11) should be used to scan for accidental secret leakage in logs and outputs.

### 2. Prompt Injection Defense
- Always wrap user input through the `Prompt Guard` (#10) and `Sanitisation Layer` (#15).
- Use the `Output Validator` (#27) to ensure LLM responses match expected schemas and do not contain malicious code or escape characters.

### 3. Data Privacy
- Default to local models (Ollama/llama.cpp) for PII-sensitive tasks.
- Use the `PII Redaction Engine` (#57) before sending data to cloud providers.
- Implement `Zero-Access Encryption` (#44) for persistent memory storage.

### 4. Dependency Security
- We pin core dependencies in `requirements.txt`.
- Every pull request runs an automated vulnerability scan using `Safety` and `Bandit`.

## üõ°Ô∏è Best Practices for Users

- **Run Locally**: Whenever possible, run PowerTools against local LLM backends to maintain data sovereignty.
- **Audit Logs**: Regularly review the structured logs generated by the `Structured Logger` (#9) to monitor for unexpected AI behaviors.
- **Provider Trust**: Only configure cloud providers (OpenAI, Anthropic, etc.) for tasks that do not involve sensitive personal or corporate data.

## üö® Reporting a Vulnerability

If you discover a security vulnerability, please do NOT open a public issue. Instead:

1. Send an email to [security@ai-powertools.io] (placeholder).
2. We will acknowledge your report within 24 hours.
3. We follow a 90-day disclosure policy‚Äîgiving us time to fix the issue before it is made public.

## üß© Security Components

The following PowerTools are specifically dedicated to security:

| # | Component | Goal |
|---|-----------|------|
| 10 | **Prompt Guard** | Prevent prompt injection attacks |
| 11 | **Privacy Layer** | PII masking and secret scanning |
| 15 | **Sanitisation Layer** | Clean input/output streams |
| 33 | **Fact Checker** | Detect hallucinations and grounding issues |
| 34 | **Evaluation Suite** | Toxicity and bias scoring |
| 44 | **Zero-Access Encryption** | Protect data at rest |
| 57 | **whoamiAI: PII Redaction** | Reversible masking for personal data |
