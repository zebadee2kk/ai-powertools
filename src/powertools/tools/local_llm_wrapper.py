from __future__ import annotations

import json
import re
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional

import httpx


@dataclass
class WrappedLLMRequest:
    """Portable request envelope for delegating work to a local LLM."""

    task: str
    user_prompt: str
    system_prompt: Optional[str] = None
    rules: List[str] = field(default_factory=list)
    context: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "task": self.task,
            "user_prompt": self.user_prompt,
            "system_prompt": self.system_prompt,
            "rules": self.rules,
            "context": self.context,
            "metadata": self.metadata,
        }


@dataclass
class WrappedLLMResponse:
    """Normalized response from the local LLM endpoint."""

    content: str
    model: str
    raw_response: Dict[str, Any]


class LocalLLMRequestWrapper:
    """
    Small utility that packages complete prompt context for local execution.

    The output of ``build_transfer_payload`` is designed to be generated by a
    public LLM and then transmitted to a local LLM service with minimal parsing.
    """

    JSON_BLOCK_PATTERN = re.compile(r"```json\s*(\{.*?\})\s*```", re.DOTALL)

    def __init__(
        self,
        *,
        base_url: str,
        model: str,
        api_key: Optional[str] = None,
        timeout_seconds: float = 30.0,
    ) -> None:
        self.base_url = base_url.rstrip("/")
        self.model = model
        self.api_key = api_key
        self.timeout_seconds = timeout_seconds

    def build_transfer_payload(self, request: WrappedLLMRequest) -> str:
        """Create a plain-text wrapper payload safe to pass across tools/models."""
        envelope = {
            "schema": "powertools.local_llm_wrapper.v1",
            "target": {"provider": "local", "model": self.model},
            "request": request.to_dict(),
        }
        return json.dumps(envelope, indent=2, sort_keys=True)

    @classmethod
    def unwrap_transfer_payload(cls, wrapped_text: str) -> Dict[str, Any]:
        """Extract wrapped JSON from a raw model response or direct JSON string."""
        stripped = wrapped_text.strip()
        if stripped.startswith("{"):
            return json.loads(stripped)

        match = cls.JSON_BLOCK_PATTERN.search(wrapped_text)
        if not match:
            raise ValueError("No wrapped JSON payload found in text")

        return json.loads(match.group(1))

    async def execute(
        self,
        request: WrappedLLMRequest,
        *,
        client: Optional[httpx.AsyncClient] = None,
    ) -> WrappedLLMResponse:
        """Send wrapped request to a local OpenAI-compatible /chat/completions endpoint."""
        payload = {
            "model": self.model,
            "messages": self._build_messages(request),
        }

        headers = {"Content-Type": "application/json"}
        if self.api_key:
            headers["Authorization"] = f"Bearer {self.api_key}"

        should_close = client is None
        http_client = client or httpx.AsyncClient(timeout=self.timeout_seconds)

        try:
            response = await http_client.post(
                f"{self.base_url}/v1/chat/completions",
                headers=headers,
                json=payload,
            )
            response.raise_for_status()
            raw = response.json()
        finally:
            if should_close:
                await http_client.aclose()

        content = raw["choices"][0]["message"]["content"]
        model = raw.get("model", self.model)
        return WrappedLLMResponse(content=content, model=model, raw_response=raw)

    @staticmethod
    def _build_messages(request: WrappedLLMRequest) -> List[Dict[str, str]]:
        messages: List[Dict[str, str]] = []
        if request.system_prompt:
            messages.append({"role": "system", "content": request.system_prompt})

        rules_block = "\n".join(f"- {rule}" for rule in request.rules)
        context_block = json.dumps(request.context, indent=2, sort_keys=True)
        user_content = (
            f"Task: {request.task}\n\n"
            f"Rules:\n{rules_block or '- none'}\n\n"
            f"Context:\n{context_block}\n\n"
            f"Prompt:\n{request.user_prompt}"
        )
        messages.append({"role": "user", "content": user_content})
        return messages
